{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "875f514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import statistics\n",
    "import re\n",
    "import datetime\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b8bb2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pods_file(file_path):\n",
    "    \n",
    "    running_pods = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        intervals = file.read().split(\"#####\")\n",
    "        pods_in_intervals = [interval.strip().split(\"\\n\") for interval in intervals]\n",
    "        for pods in pods_in_intervals:\n",
    "            action_pods = [pod for pod in pods if \"float\" in pod]\n",
    "            running_pods.append(len(action_pods))\n",
    "    \n",
    "    return statistics.mean(running_pods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f4e6feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_activation_file(file_path):\n",
    "    activations = []\n",
    "\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read each line (assuming each line contains a JSON object)\n",
    "        for line in file:\n",
    "            activ = json.loads(line.strip())\n",
    "            activations.append(activ)\n",
    "\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad671c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_timestamp_file(file_path):\n",
    "    \n",
    "    result = {}\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse the JSON object\n",
    "            k, v = line.strip().split(':')\n",
    "            result[k.strip()] = v.strip()\n",
    "    return result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "564ded71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_values(activ):\n",
    "    \n",
    "#     print(\"ACTIV\")\n",
    "#     print(activ)\n",
    "    start_time = int(activ['start'])/1000\n",
    "    end_time = int(activ['end']) / 1000\n",
    "    duration = int(activ['duration'])\n",
    "    wait_time = int(activ['annotations'][1]['value'])\n",
    "    activ_id = activ['activationId']\n",
    "    \n",
    "    # if init_annotation exists, then the function cold_started\n",
    "    try:\n",
    "        init_time = int(activ['annotations'][5]['value'])\n",
    "        cold_start = True\n",
    "    except:\n",
    "        cold_start = False\n",
    "    \n",
    "    result_dict = {\"cold_start\": cold_start, \"start_time\": start_time, \"end_time\": end_time,\n",
    "                  \"duration\": duration, \"wait_time\": wait_time}\n",
    "    \n",
    "    return {activ_id: result_dict}\n",
    "\n",
    "def get_all_activation_values(activations):\n",
    "    result = []\n",
    "    for activ in activations:\n",
    "        result.append(get_activation_values(activ))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c77d86d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_container_counts(activations, timestamps):\n",
    "    \n",
    "    exp_start = float(timestamps['Experiment_Start'])\n",
    "    exp_end = float(timestamps['Experiment_End'])\n",
    "    response_times = []\n",
    "    cold_containers = []\n",
    "    warm_containers = []\n",
    "    interval = 1\n",
    "    exp_time = int(exp_end - exp_start)\n",
    "    ptr = exp_start\n",
    "    end = exp_start + exp_time\n",
    "    c = 0\n",
    "    while(ptr < end):\n",
    "        activ_during_interval = []\n",
    "        cold_conts_in_interval = 0\n",
    "        warm_conts_in_interval = 0\n",
    "        for activ in activations:\n",
    "            activ_id = list(activ.keys())[0]\n",
    "            start_time = activ[activ_id]['start_time']\n",
    "            end_time = activ[activ_id]['end_time']\n",
    "            wait_time = activ[activ_id]['wait_time'] / 1000\n",
    "            inflight_start_time = start_time - wait_time\n",
    "            if (ptr >= inflight_start_time) and (ptr <= end_time):\n",
    "                activ_during_interval.append(activ)     \n",
    "        for activ in activ_during_interval:\n",
    "            activ_id = list(activ.keys())[0]\n",
    "            if activ[activ_id]['cold_start']:\n",
    "                cold_conts_in_interval += 1\n",
    "            else:\n",
    "                warm_conts_in_interval += 1\n",
    "        \n",
    "        cold_containers.append(cold_conts_in_interval)\n",
    "        warm_containers.append(warm_conts_in_interval)\n",
    "        ptr += interval\n",
    "        c += 1\n",
    "    avg_warm_containers = np.mean(warm_containers)\n",
    "    ci_warm_containers = stats.t.ppf(0.975, len(warm_containers)-1) * np.std(warm_containers)\n",
    "    avg_cold_containers = np.mean(cold_containers)\n",
    "    ci_cold_containers = stats.t.ppf(0.975, len(cold_containers)-1) * np.std(cold_containers)\n",
    "    \n",
    "    return avg_warm_containers, avg_cold_containers, ci_warm_containers, ci_cold_containers               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99af39c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_response_time(activations):\n",
    "    \n",
    "    resp_times = []\n",
    "    \n",
    "    for activ in activations:\n",
    "        activ_id = list(activ.keys())[0]\n",
    "        resp_time = (activ[activ_id][\"duration\"] + activ[activ_id][\"wait_time\"])/1000\n",
    "        resp_times.append(resp_time)\n",
    "    \n",
    "    avg_resp_time = np.mean(resp_times)\n",
    "    ci_resp_time = stats.t.ppf(0.975, len(resp_times)-1) * np.std(resp_times)\n",
    "    \n",
    "    \n",
    "    return avg_resp_time, ci_resp_time\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e220818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cold_start_prob(activations):\n",
    "    \n",
    "    num_requests = len(activations)\n",
    "    num_cold_starts = 0\n",
    "    for activ in activations:\n",
    "        activ_id = list(activ.keys())[0]\n",
    "        if activ[activ_id]['cold_start']:\n",
    "            num_cold_starts += 1\n",
    "            \n",
    "    return num_cold_starts/num_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8768b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_invoker_file(file_path):    \n",
    "    messages = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            messages.append(line.strip())\n",
    "    \n",
    "    return messages\n",
    "\n",
    "def extract_timestamp(line):\n",
    "    timestamp_pattern = r'\\[(.*?)\\]'\n",
    "    timestamp_match = re.search(timestamp_pattern, line)\n",
    "    if timestamp_match:\n",
    "        return timestamp_match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def timestamp_to_unix(timestamp_str):\n",
    "    timestamp = datetime.datetime.strptime(timestamp_str, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "    unix_timestamp_milliseconds = float(timestamp.timestamp())\n",
    "    return unix_timestamp_milliseconds\n",
    "\n",
    "def extract_tid(line):\n",
    "    tid_pattern = r'\\[#(.*?)\\]'\n",
    "    tid_match = re.search(tid_pattern, line)\n",
    "    if tid_match:\n",
    "        return tid_match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "                                      \n",
    "def read_invoker_files(action_name, keep_alives):\n",
    "    results = {}\n",
    "    for ka in keep_alives:\n",
    "        invoker_file_path = action_name + \"_\" + str(ka) + \"/invoker.log\"\n",
    "        invocation_logs = read_invoker_file(invoker_file_path)\n",
    "        results[ka] = invocation_logs\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_unique_containers(invocation_logs, action_name):\n",
    "    \n",
    "    pattern = r'ContainerId\\((.*?)\\)'\n",
    "    unique_containers = set()\n",
    "    for log in invocation_logs:\n",
    "        match = re.search(pattern, log)\n",
    "        if match:\n",
    "            container_id = match.group(1)\n",
    "            unique_containers.add(container_id)\n",
    "        else:\n",
    "             continue\n",
    "    action_containers = list(unique_containers)\n",
    "    action_containers = [cont for cont in action_containers if action_name in cont]\n",
    "    return action_containers\n",
    "\n",
    "\n",
    "def get_container_lifetimes(action_containers, invocation_logs):\n",
    "    \n",
    "    result = {}\n",
    "    start_pattern = \"invoker_kubeapi.create_start\"\n",
    "    delete_pattern = \"invoker_kubeapi.delete_start\"\n",
    "    for cont in action_containers:\n",
    "        container_logs = []\n",
    "        result[cont] = {}\n",
    "        for log in invocation_logs:\n",
    "            if cont in log:\n",
    "                container_logs.append(log)\n",
    "        \n",
    "        for log in container_logs:\n",
    "            if start_pattern in log:\n",
    "                result[cont][\"start\"] = timestamp_to_unix(extract_timestamp(log))\n",
    "            elif delete_pattern in log:\n",
    "                result[cont][\"delete\"] = timestamp_to_unix(extract_timestamp(log))\n",
    "        #only start, delete pattern not found\n",
    "        if len(result[cont].values()) == 1:    \n",
    "            result[cont][\"delete\"] = float('inf')\n",
    "    return result\n",
    "\n",
    "def get_active_containers(activations, container_lifetimes, invocation_logs, experiment_duration):\n",
    "    \n",
    "    first_activ_id = list(activations[0].keys())[0]\n",
    "    start_pattern = \"activationId: \" + first_activ_id\n",
    "    start_timestamp = 0\n",
    "    for log in invocation_logs:\n",
    "        if start_pattern in log:\n",
    "            start_timestamp = timestamp_to_unix(extract_timestamp(log))\n",
    "    ptr = start_timestamp\n",
    "    end_timestamp = start_timestamp + experiment_duration\n",
    "    interval = 2\n",
    "    active_containers = []\n",
    "    while(ptr < end_timestamp):\n",
    "        count = 0\n",
    "        for cont, lifetime in container_lifetimes.items():\n",
    "            if lifetime['start'] < ptr and lifetime['delete'] > ptr:\n",
    "                count += 1\n",
    "        active_containers.append(count)\n",
    "        ptr += interval\n",
    "    \n",
    "    avg_active_containers = np.mean(active_containers)\n",
    "    ci_active_containers = stats.t.ppf(0.975, len(active_containers)-1) * np.std(active_containers)\n",
    "    \n",
    "    return avg_active_containers, ci_active_containers\n",
    "\n",
    "def get_active_containers_from_invocation_logs(activations, invocation_logs, timestamps, action_name):\n",
    "    \n",
    "    action_containers = get_unique_containers(invocation_logs, action_name)\n",
    "    container_lifetimes = get_container_lifetimes(action_containers, invocation_logs)\n",
    "    experiment_duration = int(float(timestamps[\"Experiment_End\"]) - float(timestamps[\"Experiment_Start\"]))\n",
    "    \n",
    "    return get_active_containers(activations, container_lifetimes, invocation_logs, experiment_duration)\n",
    "\n",
    "def get_container_logs(action_containers, invocation_logs):\n",
    "    \n",
    "    all_container_logs = {}\n",
    "    for cont in action_containers:\n",
    "        container_logs = []\n",
    "        for log in invocation_logs:\n",
    "            if cont in log:\n",
    "                container_logs.append(log)\n",
    "        all_container_logs[cont] = container_logs\n",
    "    return all_container_logs\n",
    "\n",
    "def get_actual_keep_alives(all_container_logs, invocation_log):\n",
    "\n",
    "    delete_pattern = 'invoker_kubeapi.delete_start'\n",
    "    activation_finish_pattern = 'invoker_activationRun_finish'\n",
    "    keep_alive_times = []\n",
    "    for cont, logs in all_container_logs.items():\n",
    "        if delete_pattern in logs[-1]:\n",
    "            #print(logs[-1])\n",
    "            delete_timestamp = timestamp_to_unix(extract_timestamp(logs[-1]))\n",
    "            tid_last_func = extract_tid(logs[-2])\n",
    "            last_func_logs = [log for log in invocation_log if tid_last_func in log]\n",
    "            activ_finish_log = [log for log in last_func_logs if activation_finish_pattern in log]\n",
    "            idle_start_timestamp = timestamp_to_unix(extract_timestamp(activ_finish_log[0])) \n",
    "            keep_alive_times.append(delete_timestamp - idle_start_timestamp)\n",
    "        else:\n",
    "            continue\n",
    "    return statistics.mean(keep_alive_times), statistics.stdev(keep_alive_times) \n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbe4ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse experiment files\n",
    "def parse_files(action_name, keep_alives):\n",
    "    results = {}\n",
    "    for ka in keep_alives:\n",
    "        ka_in_ow = ka \n",
    "        activation_file_path = action_name + \"_\" + str(ka_in_ow) + \"/modified_activation.log\"\n",
    "        timestamp_file_path = action_name + \"_\" + str(ka_in_ow) + \"/timestamp.log\"\n",
    "        pods_file_path = action_name + \"_\" + str(ka_in_ow) + \"/pods.log\"\n",
    "        invoker_file_path = action_name + \"_\" + str(ka_in_ow) + \"/invoker.log\"\n",
    "        activations = read_activation_file(activation_file_path)\n",
    "        timestamps = read_timestamp_file(timestamp_file_path)\n",
    "        #running_containers = read_pods_file(pods_file_path)\n",
    "        invocation_logs = read_invoker_file(invoker_file_path)\n",
    "        #results[ka] = activations, timestamps, running_containers\n",
    "        results[ka] = activations, timestamps, invocation_logs\n",
    "    return results\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f83be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distributions(results, action_name):\n",
    "    \n",
    "    exp_results = {}\n",
    "    warm_containers = {}\n",
    "    cold_containers = {}\n",
    "    idle_containers = {}\n",
    "    response_times = {}\n",
    "    active_containers = {}\n",
    "    cold_start_probs = {}\n",
    "    ci_response_times = {}\n",
    "    ci_warm_containers = {}\n",
    "    ci_cold_containers = {}\n",
    "    ci_active_containers = {}\n",
    "    metrics = [\"running_warm\", \"running_cold\", \"running_total\", \"idle\", \"total_containers\", \"response_time\", \"cold_start_probs\"]\n",
    "    for metric in metrics:\n",
    "        exp_results[metric] = {}\n",
    "            \n",
    "    for ka in results:\n",
    "        activations = get_all_activation_values(results[ka][0])\n",
    "        timestamps = results[ka][1]\n",
    "        invocation_logs = results[ka][2]\n",
    "        avg_warm_containers, avg_cold_containers, ci_warm_container, ci_cold_container = get_experiment_container_counts(activations, timestamps)\n",
    "        avg_response_time, ci_response_time = get_experiment_response_time(activations)\n",
    "        #active_containers[ka] = results[ka][2]\n",
    "        avg_active_containers, ci_active_container = get_active_containers_from_invocation_logs(activations, invocation_logs, timestamps, action_name)\n",
    "        exp_results['running_warm'][ka] = avg_warm_containers\n",
    "        exp_results['running_cold'][ka] = avg_cold_containers\n",
    "        exp_results['running_total'][ka] = avg_warm_containers + avg_cold_containers\n",
    "        exp_results['total_containers'][ka] = avg_active_containers\n",
    "        exp_results['idle'][ka] = avg_active_containers - avg_warm_containers - avg_cold_containers\n",
    "        exp_results['response_time'][ka] = avg_response_time\n",
    "        exp_results['cold_start_probs'][ka] = get_cold_start_prob(activations)\n",
    "        \n",
    "    return exp_results\n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d0430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f84f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_alives = [1, 3, 5, 7, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 35, 40, 45, 50, 55, 60, 75, 90, 120, 150]\n",
    "action_name = \"chameleon\"\n",
    "results = parse_files(action_name, keep_alives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "caea2e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_results = get_distributions(results, action_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffd4f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Container FaaS Model\n",
    "from scipy.stats import expon\n",
    "import numpy as np\n",
    "from math import factorial, inf, exp\n",
    "\n",
    "\n",
    "def ErlangB(Rho, m):\n",
    "    \"\"\"ErlangB calculates the blocking probability for a M/G/m/m loss system.\n",
    "    The probability returned is in range [0-1].\n",
    "    It is easy to prove the correctness of the value.\n",
    "\n",
    "    Source1: https://en.wikipedia.org/wiki/Erlang_%28unit%29#Erlang_B_formula\n",
    "\n",
    "    Source2: https://stackoverflow.com/questions/23528145/how-to-wtite-erlang-b-and-erlang-c-formulas-in-python\n",
    "\n",
    "    :param Rho: Rho = lambda/mu\n",
    "    :type Rho: double\n",
    "    :param m: The number of servers.\n",
    "    :type m: int\n",
    "    :return: The blocking probability for incoming requests.\n",
    "    :rtype: double\n",
    "    \"\"\"\n",
    "    InvB = 1.0\n",
    "    for j in range(1, m+1):\n",
    "        InvB = 1.0 + InvB * (j/Rho)\n",
    "    return (1.0 / InvB)\n",
    "\n",
    "\n",
    "def print_props(props):\n",
    "    print(\"\\nProperties:\")\n",
    "    print(\"------------------\")\n",
    "    for k in props.keys():\n",
    "        print(f\"{k}: {props[k]:4.6f}\")\n",
    "    print(\"------------------\\n\")\n",
    "\n",
    "\n",
    "def get_sls_warm_count_dist(arrival_rate, warm_service_time, cold_service_time, idle_time_before_kill, maximum_concurrency=1000, faster_solution=True):\n",
    "    warm_service_rate = 1 / warm_service_time\n",
    "    cold_service_rate = 1 / cold_service_time\n",
    "    rho = arrival_rate / warm_service_rate\n",
    "\n",
    "    server_max = maximum_concurrency\n",
    "    if faster_solution:\n",
    "        server_max = min(30, maximum_concurrency)\n",
    "    server_count = 0\n",
    "\n",
    "    pblock_old = 1\n",
    "    kill_rate = 0\n",
    "\n",
    "    server_counts = [0]\n",
    "    block_rates = [arrival_rate]\n",
    "    kill_rates = [0.0]\n",
    "    cold_probs = [1]\n",
    "    running_counts = [arrival_rate * 1 * cold_service_time]\n",
    "    running_warm_counts = [0]\n",
    "    running_cold_counts = [running_counts[0]]\n",
    "    resp_times = [cold_service_time]\n",
    "\n",
    "\n",
    "    while server_count < server_max:\n",
    "        server_count += 1\n",
    "\n",
    "        # The blocking probability, the blocked requests are cold starts.\n",
    "        prob_block = ErlangB(rho, server_count)\n",
    "        block_rate = prob_block * arrival_rate\n",
    "\n",
    "        # The difference between blocked requests in m-1 and m is the requests\n",
    "        # served on the m'th servers.\n",
    "        prob_mth_server = pblock_old - prob_block\n",
    "        pblock_old = prob_block\n",
    "\n",
    "        # prob of no request in the next idle_time_before_kill for each request\n",
    "        prob_kill_mth = 1 - \\\n",
    "            expon.cdf(idle_time_before_kill, scale=1 /\n",
    "                      (arrival_rate * prob_mth_server))\n",
    "        if prob_kill_mth > 0:\n",
    "            # expected number of requests before the last one\n",
    "            exp_request_before_kill = 1 / prob_kill_mth\n",
    "\n",
    "            L = arrival_rate * prob_mth_server\n",
    "            T = idle_time_before_kill + warm_service_time\n",
    "            # average time between requests, when those requests wouldn't\n",
    "            # be so far apart that results in killing the container.\n",
    "#             avg_inter_arrival = (-1 * T * exp(-1 * L * T)) + \\\n",
    "#                 (1 - exp(-1 * L * T)) / L\n",
    "            \n",
    "            avg_inter_arrival = 1/L\n",
    "\n",
    "            # Time it takes for a container to be killed after being created.\n",
    "            inter_kill_time = idle_time_before_kill + \\\n",
    "                (exp_request_before_kill - 1) * avg_inter_arrival\n",
    "            kill_rate += 1 / inter_kill_time\n",
    "        else:\n",
    "            kill_rate += 0\n",
    "\n",
    "        # Average number of warm containers serving the requests\n",
    "        running_count_warm = arrival_rate * \\\n",
    "            (1 - prob_block) * warm_service_time\n",
    "        running_count_cold = arrival_rate * prob_block * cold_service_time\n",
    "        running_count = running_count_warm + running_count_cold\n",
    "\n",
    "        # Average Response Time\n",
    "        resp_time = (prob_block * cold_service_time) + \\\n",
    "            ((1 - prob_block) * warm_service_time)\n",
    "\n",
    "        # If we reached maximum concurrency, we don't have cold starts any more!\n",
    "        if server_count == maximum_concurrency:\n",
    "            resp_time = warm_service_time\n",
    "            running_count_cold = 0\n",
    "            running_count = running_count_warm\n",
    "\n",
    "        # Record properties for each state in CTMC\n",
    "        server_counts.append(server_count)\n",
    "        block_rates.append(block_rate)\n",
    "        kill_rates.append(kill_rate)\n",
    "        cold_probs.append(prob_block)\n",
    "        running_counts.append(running_count)\n",
    "        resp_times.append(resp_time)\n",
    "        running_warm_counts.append(running_count_warm)\n",
    "        running_cold_counts.append(running_count_cold)\n",
    "\n",
    "        if faster_solution:\n",
    "            if block_rate > kill_rate:\n",
    "                server_max = min(server_count + 30, maximum_concurrency)\n",
    "\n",
    "    server_counts = np.array(server_counts)\n",
    "    block_rates = np.array(block_rates)\n",
    "    kill_rates = np.array(kill_rates)\n",
    "    cold_probs = np.array(cold_probs)\n",
    "    running_counts = np.array(running_counts)\n",
    "    resp_times = np.array(resp_times)\n",
    "    running_warm_counts = np.array(running_warm_counts)\n",
    "    running_cold_counts = np.array(running_cold_counts)\n",
    "\n",
    "    states_counts = len(server_counts)\n",
    "    Q = np.zeros((states_counts, states_counts))\n",
    "    for i in range(states_counts):\n",
    "        out_rate = 0\n",
    "        if i > 0:\n",
    "            Q[i, i-1] = kill_rates[i]\n",
    "            out_rate += kill_rates[i]\n",
    "        if i < states_counts-1:\n",
    "            Q[i, i+1] = (block_rates[i] * cold_service_rate) / (block_rates[i] + cold_service_rate)\n",
    "            out_rate += (block_rates[i] * cold_service_rate) / (block_rates[i] + cold_service_rate)\n",
    "        Q[i, i] = 0 - out_rate\n",
    "\n",
    "    Q[:, 0] = 1\n",
    "    y = np.zeros((1, Q.shape[0]))\n",
    "    y[0, 0] = 1\n",
    "\n",
    "    solution = np.linalg.solve(np.array(Q.T), np.array(y.T))\n",
    "    solution = solution.reshape(solution.shape[0],)\n",
    "    solution[solution < 0] = 0\n",
    "\n",
    "    # if hasn't reached maximum concurrency, we can't measure it via float (accuracy is not enough, out guess is zero)\n",
    "    rejection_prob = 0\n",
    "    rejection_rate = 0\n",
    "    # when we reach maximum concurrency, cold starts can't happen, so they are rejections\n",
    "    if server_max == maximum_concurrency:\n",
    "        rejection_prob = cold_probs[-1] * solution[-1]\n",
    "        cold_probs[-1] = 0\n",
    "        rejection_rate = block_rates[-1] * solution[-1]\n",
    "        block_rates[-1] = 0\n",
    "\n",
    "    avg_server_count = np.dot(server_counts, solution)\n",
    "    avg_running_count = np.dot(running_counts, solution)\n",
    "    avg_running_warm_count = np.dot(running_warm_counts, solution)\n",
    "    avg_running_cold_count = np.dot(running_cold_counts, solution)\n",
    "    avg_server_count_total = avg_server_count + avg_running_cold_count # total count is average of warm + average of running cold\n",
    "    avg_resp_time = np.dot(resp_times, solution)\n",
    "    avg_idle_count = avg_server_count - avg_running_warm_count\n",
    "    cold_prob = np.dot(cold_probs, solution)\n",
    "    avg_utilization = avg_running_warm_count / avg_server_count\n",
    "    \n",
    "    return {\n",
    "        \"avg_server_count\": avg_server_count,\n",
    "        \"avg_server_count_total\": avg_server_count_total,\n",
    "        \"avg_running_count\": avg_running_count,\n",
    "        \"avg_running_warm_count\": avg_running_warm_count,\n",
    "        \"avg_running_cold_count\": avg_running_cold_count,\n",
    "        \"avg_idle_count\": avg_idle_count,\n",
    "        \"cold_prob\": cold_prob,\n",
    "        \"avg_utilization\": avg_utilization,\n",
    "        \"avg_resp_time\": avg_resp_time,\n",
    "        \"rejection_prob\": rejection_prob,\n",
    "        \"rejection_rate\": rejection_rate,\n",
    "    }\n",
    "#     return {\n",
    "#         \"running_warm\": avg_running_warm_count,\n",
    "#         \"running_cold\": avg_running_cold_count,\n",
    "#         \"running_total\": avg_running_count,\n",
    "#         \"idle\": avg_idle_count,\n",
    "#         \"total_containers\": avg_server_count_total,\n",
    "#         \"response_time\": avg_resp_time,\n",
    "#         \"cold_start_probs\": cold_prob\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4587202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model_dists(arrival_rate, warm_service_time, cold_service_time, keep_alives):\n",
    "    \n",
    "    model_results = {}\n",
    "    metrics = [\"running_warm\", \"running_cold\", \"running_total\", \"idle\", \"total_containers\", \"response_time\", \"cold_start_probs\"]\n",
    "    for metric in metrics:\n",
    "        model_results[metric] = {}\n",
    "    \n",
    "    for ka in keep_alives:\n",
    "        model_result = get_sls_warm_count_dist(arrival_rate, warm_service_time, cold_service_time, ka)\n",
    "        model_results['running_warm'][ka] = model_result['avg_running_warm_count']\n",
    "        model_results['running_cold'][ka] = model_result['avg_running_cold_count']\n",
    "        model_results['running_total'][ka] = model_result['avg_running_count']\n",
    "        model_results['total_containers'][ka] = model_result['avg_server_count_total']\n",
    "        model_results['idle'][ka] = model_result['avg_idle_count']\n",
    "        model_results['response_time'][ka] = model_result['avg_resp_time']\n",
    "        model_results['cold_start_probs'][ka] = model_result['cold_prob']\n",
    "        \n",
    "        \n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec2ce1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrival_rate = 1\n",
    "# warm_service_time = 0.072\n",
    "# cold_service_time = 3.483\n",
    "# wa_model_resp_time = 0.153\n",
    "# # spin_resp_std_dev = 0.9214\n",
    "# # spin_executors_std_dev = 2.6944\n",
    "# spin_exp_resp_time = 0.166\n",
    "# spin_busy_executors = 0.169\n",
    "# #ci_spin_busy_executors = stats.t.ppf(0.975, 1) * np.std(spin_executors_std_dev)\n",
    "# #ci_spin_resp_time = stats.t.ppf(0.975, 1) * np.std(spin_resp_std_dev)\n",
    "# wa_model_busy_executors = 0.153\n",
    "# model_results = gen_model_dists(arrival_rate, warm_service_time, cold_service_time, keep_alives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d74a5c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cold_response_time': 3.5557, 'warm_response_time': 0.068}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resp_time = {}\n",
    "with open(f\"{action_name}_container_model_response_time.json\", 'r') as file:\n",
    "    model_resp_time = json.load(file)\n",
    "model_resp_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ca2494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_rate = 1\n",
    "warm_service_time = model_resp_time[\"warm_response_time\"]\n",
    "cold_service_time = model_resp_time[\"cold_response_time\"]\n",
    "model_results = gen_model_dists(arrival_rate, warm_service_time, cold_service_time, keep_alives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3054426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json = {}\n",
    "output_json[\"OpenWhisk\"] = exp_results\n",
    "output_json[\"Model\"] = model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4761e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json_string = json.dumps(output_json)\n",
    "file_path = f\"{action_name}_container_results.json\"\n",
    "\n",
    "# Open the file in write mode and write the JSON string\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(output_json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430320fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
